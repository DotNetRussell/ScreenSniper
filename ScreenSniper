#!/usr/bin/python3

import cv2
import pytesseract
from PIL import Image
import re
import sys
import numpy as np
import argparse
import os
import json
import xml.etree.ElementTree as ET
from xml.dom import minidom

# Function to preprocess image for OCR
def preprocess_image(image_path, verbose=False):
    if verbose:
        print("Starting image preprocessing...")
    # Load image with OpenCV
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"Could not load image at {image_path}")
    if verbose:
        print("Image loaded successfully.")
    
    # Resize to a higher resolution to improve text detection
    scale_factor = 2
    img = cv2.resize(img, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_CUBIC)
    if verbose:
        cv2.imwrite(".debug_resized.png", img)
        print("Image resized and saved as debug_resized.png")
    
    # Convert to grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    if verbose:
        cv2.imwrite(".debug_grayscale.png", gray)
        print("Converted to grayscale and saved as debug_grayscale.png")
    
    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    gray = clahe.apply(gray)
    if verbose:
        cv2.imwrite(".debug_clahe.png", gray)
        print("Applied CLAHE and saved as debug_clahe.png")
    
    # Apply adaptive thresholding
    thresh = cv2.adaptiveThreshold(
        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 21, 5
    )
    if verbose:
        cv2.imwrite(".debug_threshold.png", thresh)
        print("Applied adaptive thresholding and saved as debug_threshold.png")
    
    # Minimal dilation to connect broken characters
    kernel = np.ones((2, 2), np.uint8)
    dilated = cv2.dilate(thresh, kernel, iterations=1)
    if verbose:
        cv2.imwrite(".debug_dilated.png", dilated)
        print("Applied dilation and saved as debug_dilated.png")
    
    # Save preprocessed image for OCR
    cv2.imwrite(".preprocessed.png", dilated)
    if verbose:
        print("Final preprocessed image saved as preprocessed.png")
    return dilated

# Function to extract text from image using Tesseract OCR
def extract_text(image_path, verbose=False):
    try:
        # Use Pillow to open image for Tesseract
        img = Image.open(image_path)
        # Try different page segmentation modes
        custom_config = r'--oem 3 --psm 6'
        text = pytesseract.image_to_string(img, config=custom_config)
        if not text.strip():
            if verbose:
                print("PSM 6 failed, trying PSM 3...")
            custom_config = r'--oem 3 --psm 3'
            text = pytesseract.image_to_string(img, config=custom_config)
        if not text.strip():
            if verbose:
                print("PSM 3 failed, trying PSM 11...")
            custom_config = r'--oem 3 --psm 11'
            text = pytesseract.image_to_string(img, config=custom_config)
        if not text.strip():
            return "OCR Error: No text extracted"
        if verbose:
            print(f"Extracted Text: {text}")
        return text.strip()
    except Exception as e:
        return f"OCR Error: {str(e)}"

# Function to load templates from the detectionPatterns directory
def load_templates(template_dir="detectionPatterns"):
    templates = []
    if not os.path.isdir(template_dir):
        print(f"Error: Template directory '{template_dir}' does not exist.")
        sys.exit(1)

    for filename in os.listdir(template_dir):
        if filename.endswith(".json"):
            filepath = os.path.join(template_dir, filename)
            try:
                with open(filepath, "r") as f:
                    template = json.load(f)
                    templates.append(template)
            except Exception as e:
                print(f"Warning: Failed to load template '{filename}': {str(e)}")
    if not templates:
        print(f"Error: No valid templates found in '{template_dir}'.")
        sys.exit(1)
    return templates

# Function to generate meta tags based on extracted text and templates
def generate_meta_tags(text, templates):
    meta_tags = []
    text_lower = text.lower()

    # Handle OCR failure
    if text.startswith("OCR Error") and verbose:
        return [
            "Error: Unable to generate meta tags due to OCR failure",
            "Suggestion: Possible Text Detection Failure - Review Screenshot Manually",
            "Debug: Check debug_*.png files for preprocessing steps (run with --verbose)"
        ]

    # Check each template
    for template in templates:
        # Check positive conditions: at least one must match
        conditions_met = any(keyword.lower() in text_lower for keyword in template["conditions"])

        # Check negative conditions: none must match
        negative_conditions_met = False
        if "negative_conditions" in template:
            negative_conditions_met = any(keyword.lower() in text_lower for keyword in template["negative_conditions"])

        # Apply the template only if conditions are met and negative conditions are not met
        if conditions_met and not negative_conditions_met:
            # Add the meta tags from the template
            meta_tags.extend(template["meta_tags"])

            # Handle additional checks (e.g., sensitive file extensions)
            if "additional_checks" in template and "sensitive_extensions" in template["additional_checks"]:
                for ext in template["additional_checks"]["sensitive_extensions"]:
                    if ext.lower() in text_lower:
                        meta_tags.append(f"Security: Exposed File Type ({ext})")
                        meta_tags.append("SecurityRisk: Potential Sensitive File Exposure")

    # If no templates matched, add a default "Unknown" page type
    if not any(tag.startswith("PageType:") for tag in meta_tags):
        meta_tags.append("PageType: Unknown")

    # Detect version information (strict regex for version numbers)
    version_pattern = r"version\s*[\d]+\.[\d]+\.?[\d]*"
    versions = re.findall(version_pattern, text_lower)
    for version in versions:
        meta_tags.append(f"VersionInfo: {version.strip()}")
        meta_tags.append("SecurityRisk: Version Disclosure")

    return meta_tags

# Function to format output based on the specified format
def format_output(meta_tags, output_format):
    if output_format == "normal":
        return "\n".join(meta_tags)
    elif output_format == "json":
        return json.dumps({"meta_tags": meta_tags}, indent=4)
    elif output_format == "xml":
        root = ET.Element("result")
        meta_tags_elem = ET.SubElement(root, "meta_tags")
        for tag in meta_tags:
            tag_elem = ET.SubElement(meta_tags_elem, "meta_tag")
            tag_elem.text = tag
        return minidom.parseString(ET.tostring(root)).toprettyxml(indent="    ").strip()
    else:
        raise ValueError(f"Unsupported output format: {output_format}")

# Main function to analyze screenshot and generate meta tags
def analyze_screenshot(image_path, templates, verbose=False):
    try:
        # Preprocess image
        preprocess_image(image_path, verbose)
        
        # Extract text using OCR
        extracted_text = extract_text(".preprocessed.png", verbose)
        
        # Generate meta tags
        meta_tags = generate_meta_tags(extracted_text, templates)
        meta_tags.append(f"File Path: {image_path}")
        # Return results
        return extracted_text, meta_tags
    except Exception as e:
        return f"Error: {str(e)}", ["Error: Analysis failed"]

# Main execution with command-line arguments
if __name__ == "__main__":
    # Set up argument parser
    parser = argparse.ArgumentParser(description="Analyze a webpage screenshot and generate meta tags for technology and security insights.")
    parser.add_argument("image_path", type=str, help="Path to the screenshot image file (e.g., screenshot.png)")
    parser.add_argument("--verbose", action="store_true", help="Enable verbose output for debugging")
    parser.add_argument("--output-format", choices=["normal", "json", "xml"], default="normal", help="Output format: normal (default), json, or xml")
    
    # Parse arguments
    args = parser.parse_args()
    screenshot_path = args.image_path
    verbose = args.verbose
    output_format = args.output_format

    # Validate that the file exists
    if not os.path.isfile(screenshot_path):
        print(f"Error: The file '{screenshot_path}' does not exist.")
        sys.exit(1)

    # Validate that the file is an image (basic check based on extension)
    valid_extensions = (".png", ".jpg", ".jpeg", ".gif", ".bmp")
    if not screenshot_path.lower().endswith(valid_extensions):
        print(f"Error: The file '{screenshot_path}' must be an image file ({', '.join(valid_extensions)}).")
        sys.exit(1)

    # Load templates
    templates = load_templates("detectionPatterns")

    # Analyze the screenshot
    extracted_text, meta_tags = analyze_screenshot(screenshot_path, templates, verbose)

    # Output results in the specified format
    if verbose:
        print("Analysis Results:")
        print(f"File Path: {screenshot_path}")
        print(f"Extracted Text: {extracted_text}")
        print("Meta Tags:")
    print(format_output(meta_tags, output_format))
