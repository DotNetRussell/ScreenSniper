#!/usr/bin/python3

import cv2
import pytesseract
from PIL import Image
import re
import sys
import numpy as np
import argparse
import os
import json
import xml.etree.ElementTree as ET
from xml.dom import minidom
import subprocess
import shutil
import base64
import datetime

# Function to check if Tesseract is installed
def check_tesseract(verbose=False):
    if not shutil.which("tesseract"):
        error_msg = "Tesseract OCR is not installed or not in PATH. Install with 'apt-get install tesseract-ocr' (Debian/Ubuntu) and 'pip install pytesseract'."
        if verbose:
            print(error_msg)
        return False, error_msg
    return True, ""

# Function to preprocess image for OCR
def preprocess_image(image_path, verbose=False):
    if verbose:
        print(f"Starting image preprocessing for {image_path}...")
    # Load image with OpenCV
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"Could not load image at {image_path}")
    if verbose:
        print("Image loaded successfully.")
    
    # Resize to a higher resolution to improve text detection
    scale_factor = 4
    img = cv2.resize(img, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_CUBIC)
    if verbose:
        cv2.imwrite(".debug_resized.png", img)
        print("Image resized and saved as debug_resized.png")
    
    # Convert to grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    if verbose:
        cv2.imwrite(".debug_grayscale.png", gray)
        print("Converted to grayscale and saved as debug_grayscale.png")
    
    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    gray = clahe.apply(gray)
    if verbose:
        cv2.imwrite(".debug_clahe.png", gray)
        print("Applied CLAHE and saved as debug_clahe.png")
    
    # Apply adaptive thresholding
    thresh = cv2.adaptiveThreshold(
        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 21, 5
    )
    if verbose:
        cv2.imwrite(".debug_threshold.png", thresh)
        print("Applied adaptive thresholding and saved as debug_threshold.png")
    
    # Minimal dilation to connect broken characters
    kernel = np.ones((2, 2), np.uint8)
    dilated = cv2.dilate(thresh, kernel, iterations=1)
    if verbose:
        cv2.imwrite(".debug_dilated.png", dilated)
        print("Applied dilation and saved as debug_dilated.png")
    
    # Save preprocessed image for OCR
    cv2.imwrite(".preprocessed.png", dilated)
    if verbose:
        print("Final preprocessed image saved as preprocessed.png")
    return dilated

# Function to extract text from image using Tesseract OCR
def extract_text(image_path, verbose=False):
    # Check Tesseract availability
    tesseract_ok, error_msg = check_tesseract(verbose)
    if not tesseract_ok:
        return f"OCR Error: {error_msg}"
    
    try:
        # Use Pillow to open image for Tesseract
        img = Image.open(image_path)
        # Try different page segmentation modes
        custom_config = r'--oem 3 --psm 6'
        text = pytesseract.image_to_string(img, config=custom_config)
        if not text.strip():
            if verbose:
                print("PSM 6 failed, trying PSM 3...")
            custom_config = r'--oem 3 --psm 3'
            text = pytesseract.image_to_string(img, config=custom_config)
        if not text.strip():
            if verbose:
                print("PSM 3 failed, trying PSM 11...")
            custom_config = r'--oem 3 --psm 11'
            text = pytesseract.image_to_string(img, config=custom_config)
        if not text.strip():
            return "OCR Error: No text extracted"
        if verbose:
            print(f"Extracted Text: {text}")
        return text.strip()
    except Exception as e:
        return f"OCR Error: {str(e)}"

# Function to load templates from the detectionPatterns directory
def load_templates(template_dir="detectionPatterns"):
    templates = []
    if not os.path.isdir(template_dir):
        print(f"Error: Template directory '{template_dir}' does not exist.")
        sys.exit(1)

    for filename in os.listdir(template_dir):
        if filename.endswith(".json"):
            filepath = os.path.join(template_dir, filename)
            try:
                with open(filepath, "r") as f:
                    template = json.load(f)
                    templates.append(template)
            except Exception as e:
                print(f"Warning: Failed to load template '{filename}': {str(e)}")
    if not templates:
        print(f"Error: No valid templates found in '{template_dir}'.")
        sys.exit(1)
    return templates

# Function to generate meta tags based on extracted text and templates
def generate_meta_tags(text, templates):
    meta_tags = []
    text_lower = text.lower()

    # Handle OCR failure
    if text.startswith("OCR Error"):
         return []
#        return [
#            "Error: Unable to generate meta tags due to OCR failure",
#            "Suggestion: Possible Text Detection Failure - Review Screenshot Manually",
#            "Debug: Check debug_*.png files for preprocessing steps (run with --verbose)"
#        ]

    # Check each template
    for template in templates:
        # Check positive conditions: at least one must match
        conditions_met = any(keyword.lower() in text_lower for keyword in template["conditions"])

        # Check negative conditions: none must match
        negative_conditions_met = False
        if "negative_conditions" in template:
            negative_conditions_met = any(keyword.lower() in text_lower for keyword in template["negative_conditions"])

        # Apply the template only if conditions are met and negative conditions are not met
        if conditions_met and not negative_conditions_met:
            # Add the meta tags from the template
            meta_tags.extend(template["meta_tags"])

            # Handle additional checks (e.g., sensitive file extensions)
            if "additional_checks" in template and "sensitive_extensions" in template["additional_checks"]:
                for ext in template["additional_checks"]["sensitive_extensions"]:
                    if ext.lower() in text_lower:
                        meta_tags.append(f"Security: Exposed File Type ({ext})")
                        meta_tags.append("SecurityRisk: Potential Sensitive File Exposure")

    # If no templates matched, add a default "Unknown" page type
    if not any(tag.startswith("PageType:") for tag in meta_tags):
        meta_tags.append("PageType: Unknown")

    # Detect version information (strict regex for version numbers)
    version_pattern = r"version\s*[\d]+\.[\d]+\.?[\d]*"
    versions = re.findall(version_pattern, text_lower)
    for version in versions:
        meta_tags.append(f"VersionInfo: {version.strip()}")
        meta_tags.append("SecurityRisk: Version Disclosure")

    return meta_tags

# Function to format output based on the specified format
def format_output(meta_tags, output_format):
    if output_format == "normal":
        return "\n".join(meta_tags)
    elif output_format == "json":
        return json.dumps({"meta_tags": meta_tags}, indent=4)
    elif output_format == "xml":
        root = ET.Element("result")
        meta_tags_elem = ET.SubElement(root, "meta_tags")
        for tag in meta_tags:
            tag_elem = ET.SubElement(meta_tags_elem, "meta_tag")
            tag_elem.text = tag
        return minidom.parseString(ET.tostring(root)).toprettyxml(indent="    ").strip()
    else:
        raise ValueError(f"Unsupported output format: {output_format}")

# Function to generate and save report for multiple images
def generate_report(results, output_format, verbose=False, include_extracted=False):
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    report_filename = f"screensniper_report_{timestamp}.{output_format}"
    
    # Initialize report content
    report_content = [
        f"ScreenSniper Analysis Report",
        f"Generated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        f"Output Format: {output_format}",
        f"Total Images Processed: {len(results)}",
        "=" * 50
    ]
    
    # JSON and XML structures
    report_dict = {
        "report": {
            "generated": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "output_format": output_format,
            "total_images": len(results),
            "results": []
        }
    }
    xml_root = ET.Element("report")
    ET.SubElement(xml_root, "generated").text = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    ET.SubElement(xml_root, "output_format").text = output_format
    ET.SubElement(xml_root, "total_images").text = str(len(results))
    xml_results = ET.SubElement(xml_root, "results")
    
    # Process each result
    for result in results:
        image_path = result["image_path"]
        extracted_text = result["extracted_text"]
        meta_tags = result["meta_tags"]
        formatted_output = format_output(meta_tags, output_format)
        
        # Normal format content
        report_content.extend([
            f"Image Path: {image_path}",
            "-" * 50
        ])
        
        # Only include extracted text if verbose or include_extracted is set
        if verbose or include_extracted:
            try:
                base64_text = base64.b64encode(extracted_text.encode('utf-8')).decode('utf-8')
                report_content.extend([
                    "Extracted Text (Base64):",
                    base64_text,
                    "-" * 50
                ])
            except Exception as e:
                report_content.extend([
                    f"Extracted Text Error: Failed to encode text to Base64: {str(e)}",
                    "-" * 50
                ])
        
        report_content.extend([
            "Meta Tags:",
            formatted_output,
            "=" * 50
        ])
        
        # JSON format content
        json_result = {
            "image_path": image_path,
            "meta_tags": meta_tags
        }
        if verbose or include_extracted:
            try:
                json_result["extracted_text_base64"] = base64.b64encode(extracted_text.encode('utf-8')).decode('utf-8')
            except Exception as e:
                json_result["extracted_text_error"] = f"Failed to encode text to Base64: {str(e)}"
        report_dict["report"]["results"].append(json_result)
        
        # XML format content
        xml_result = ET.SubElement(xml_results, "result")
        ET.SubElement(xml_result, "image_path").text = image_path
        if verbose or include_extracted:
            try:
                base64_text = base64.b64encode(extracted_text.encode('utf-8')).decode('utf-8')
                ET.SubElement(xml_result, "extracted_text_base64").text = base64_text
            except Exception as e:
                ET.SubElement(xml_result, "extracted_text_error").text = f"Failed to encode text to Base64: {str(e)}"
        xml_meta_tags = ET.SubElement(xml_result, "meta_tags")
        for tag in meta_tags:
            tag_elem = ET.SubElement(xml_meta_tags, "meta_tag")
            tag_elem.text = tag
    
    # Finalize report text based on format
    if output_format == "normal":
        report_text = "\n".join(report_content)
    elif output_format == "json":
        report_text = json.dumps(report_dict, indent=4)
    elif output_format == "xml":
        report_text = minidom.parseString(ET.tostring(xml_root)).toprettyxml(indent="    ").strip()
    
    # Print to console
    print(report_text)
    
    # Save to file
    try:
        with open(report_filename, "w", encoding="utf-8") as f:
            f.write(report_text)
        if verbose:
            print(f"Report saved to {report_filename}")
    except Exception as e:
        print(f"Error saving report: {str(e)}")
    
    return report_text

# Function to call text_classifier.py with OCR'd text
def run_text_classifier(text, meta_tags, verbose=False):
    try:
        # Check if text_classifier.py exists
        classifier_path = os.path.join(os.getcwd(), "AI_Page_Classifier", "text_classifier.py")
        if not os.path.isfile(classifier_path):
            if verbose:
                print("Text classifier script (text_classifier.py) not found in AI_Page_Classifier directory")
            return {
                "ClassifierError": "text_classifier.py not found",
                "Suggestion": "Ensure text_classifier.py is in the AI_Page_Classifier directory"
            }
        
        tags = " ".join(meta_tags)
        text = text + tags

        # Escape quotes in text to handle special characters
        escaped_text = text.replace('"', '\\"')
        cmd = ['python3', classifier_path, escaped_text, '--automation']
        if verbose:
            print(f"Running text classifier command: {' '.join(cmd[:2])} [sanitized text] --automation")
        
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            check=False  # Don't raise on non-zero exit code
        )
        
        # Debug: Log stdout, stderr, and return code in verbose mode
        if verbose:
            print(f"Text classifier return code: {result.returncode}")
            print(f"Text classifier stdout: {result.stdout!r}")
            print(f"Text classifier stderr: {result.stderr!r}")
        
        # Check for subprocess failure
        if result.returncode != 0:
            if verbose:
                print(f"Text classifier failed with exit code {result.returncode}")
            return {
                "ClassifierError": f"Subprocess failed with exit code {result.returncode}: {result.stderr}",
                "Suggestion": "Check text_classifier.py dependencies (model.pt, training_data.json, vocabulary.json)"
            }
        
        # Check if stdout is empty
        if not result.stdout.strip():
            if verbose:
                print("Text classifier produced no output")
            return {
                "ClassifierError": "Text classifier produced no output",
                "Suggestion": "Ensure text_classifier.py is configured correctly"
            }
        
        # Parse JSON output
        try:
            output = json.loads(result.stdout)
        except json.JSONDecodeError as e:
            if verbose:
                print(f"Error parsing text classifier output: {e}")
            return {
                "ClassifierError": f"Failed to parse classifier output: {e}",
                "Suggestion": "Check text_classifier.py for non-JSON output or errors"
            }
        
        if "error" in output:
            if verbose:
                print(f"Text classifier error: {output['error']}")
            return {
                "ClassifierError": output['error'],
                "Suggestion": "Review text_classifier.py configuration or input text"
            }
        
        # Extract results
        meta_tags = []
        meta_tags.append(f"Interesting Page: {output.get('is_interesting', False)}")
        meta_tags.append(f"ClassifierProbability: {output.get('probability', 0.0):.4f}")
        if verbose:
            print(f"Text classifier results: is_interesting={output.get('is_interesting', False)}, probability={output.get('probability', 0.0)}")
        
        return meta_tags
    
    except subprocess.CalledProcessError as e:
        if verbose:
            print(f"Text classifier subprocess failed: {e.stderr}")
        return {
            "ClassifierError": f"Subprocess failed: {e.stderr}",
            "Suggestion": "Check text_classifier.py dependencies"
        }
    except FileNotFoundError:
        if verbose:
            print("Text classifier script (text_classifier.py) not found")
        return {
            "ClassifierError": "text_classifier.py not found",
            "Suggestion": "Ensure text_classifier.py is in the AI_Page_Classifier directory"
        }
    except Exception as e:
        if verbose:
            print(f"Unexpected error running text classifier: {str(e)}")
        return {
            "ClassifierError": str(e),
            "Suggestion": "Review text_classifier.py execution environment"
        }

# Main function to analyze screenshot and generate meta tags
def analyze_screenshot(image_path, templates, verbose=False, ai=False, include_extracted=False, detection_pattern=False):
    try:
        # Preprocess image
        preprocess_image(image_path, verbose)
        
        # Extract text using OCR
        extracted_text = extract_text(".preprocessed.png", verbose)
        
        # Generate meta tags from templates only if --detection-pattern is set
        meta_tags = []
        if detection_pattern:
            meta_tags = generate_meta_tags(extracted_text, templates)

        # Run text classifier if --ai flag is set
        if ai and not extracted_text.startswith("OCR Error"):
            classifier_results = run_text_classifier(extracted_text, meta_tags, verbose)
            if isinstance(classifier_results, list):
                # If classifier returns meta tags, append them
                # Only add PageType: Interesting if no other PageType exists
                if not any(tag.startswith("PageType:") for tag in meta_tags) and "PageType: Interesting" in classifier_results:
                    meta_tags.append("PageType: Interesting")
                meta_tags.extend([tag for tag in classifier_results if not tag.startswith("PageType:") or tag == "PageType: Interesting"])
            else:
                # Handle error case
                meta_tags.append(classifier_results.get("ClassifierError", "ClassifierError: Unknown error"))
                if "Suggestion" in classifier_results:
                    meta_tags.append(classifier_results["Suggestion"])
        
        # Only include extracted text (Base64 encoded) if --include-extracted or --verbose is set
        if (include_extracted or verbose) and not extracted_text.startswith("OCR Error"):
            try:
                base64_text = base64.b64encode(extracted_text.encode('utf-8')).decode('utf-8')
                meta_tags.append(f"ExtractedTextBase64: {base64_text}")
            except Exception as e:
                meta_tags.append(f"ExtractedTextError: Failed to encode text to Base64: {str(e)}")
        
        meta_tags.append(f"File Path: {image_path}")
        
        return extracted_text, meta_tags
    except Exception as e:
        return f"Error: {str(e)}", ["Error: Analysis failed"]

# Function to process all images in a directory
def process_directory(directory_path, templates, verbose=False, ai=False, include_extracted=False, detection_pattern=False, report=False, output_format="normal"):
    valid_extensions = (".png", ".jpg", ".jpeg", ".gif", ".bmp")
    results = []
    
    if not os.path.isdir(directory_path):
        print(f"Error: The directory '{directory_path}' does not exist.")
        sys.exit(1)
    
    # Collect all valid image files
    image_files = [f for f in os.listdir(directory_path) if f.lower().endswith(valid_extensions)]
    
    if not image_files:
        print(f"Error: No valid image files found in '{directory_path}'.")
        sys.exit(1)
    
    if verbose:
        print(f"Found {len(image_files)} image(s) in directory: {directory_path}")
    
    # Process each image
    for image_file in image_files:
        image_path = os.path.join(directory_path, image_file)
        if verbose:
            print(f"\nProcessing image: {image_path}")
        
        # Analyze the screenshot
        extracted_text, meta_tags = analyze_screenshot(image_path, templates, verbose, ai, include_extracted, detection_pattern)
        
        # Store results
        results.append({
            "image_path": image_path,
            "extracted_text": extracted_text,
            "meta_tags": meta_tags
        })
        
        # Handle output for this image (console only unless report flag is set)
        if not report:
            if verbose:
                print("Analysis Results:")
                print(f"File Path: {image_path}")
                if verbose or include_extracted:
                    try:
                        base64_text = base64.b64encode(extracted_text.encode('utf-8')).decode('utf-8')
                        print(f"Extracted Text (Base64): {base64_text}")
                    except Exception as e:
                        print(f"Extracted Text Error: Failed to encode text to Base64: {str(e)}")
                print("Meta Tags:")
            print(format_output(meta_tags, output_format))
            print("-" * 50)
    
    # Generate single report for all images if report flag is set
    if report:
        generate_report(results, output_format, verbose, include_extracted)
    
    return results

# Main execution with command-line arguments
if __name__ == "__main__":
    # Set up argument parser
    parser = argparse.ArgumentParser(description="Analyze a webpage screenshot or directory of screenshots and generate meta tags for technology and security insights.")
    parser.add_argument("--image_path", type=str, help="Path to the screenshot image file (e.g., screenshot.png)")
    parser.add_argument("--directory", type=str, help="Path to a directory containing screenshot image files")
    parser.add_argument("--verbose", action="store_true", help="Enable verbose output for debugging")
    parser.add_argument("--output-format", choices=["normal", "json", "xml"], default="normal", help="Output format: normal (default), json, or xml")
    parser.add_argument("--ai", action="store_true", help="Enable AI text classification using text_classifier.py")
    parser.add_argument("--include-extracted", action="store_true", help="Include Base64-encoded extracted text as a meta tag")
    parser.add_argument("--detection-pattern", action="store_true", help="Include meta tags from detection patterns")
    parser.add_argument("--report", action="store_true", help="Generate a single report file with analysis results for all images")
    
    # Parse arguments
    args = parser.parse_args()
    image_path = args.image_path
    directory_path = args.directory
    verbose = args.verbose
    output_format = args.output_format
    ai = args.ai
    include_extracted = args.include_extracted
    detection_pattern = args.detection_pattern
    report = args.report

    # Validate input: either image_path or directory must be provided, but not both
    if (image_path and directory_path) or (not image_path and not directory_path):
        print("Error: Exactly one of --image_path or --directory must be provided.")
        sys.exit(1)

    # Load templates
    templates = load_templates("detectionPatterns")

    if directory_path:
        # Process directory of images
        process_directory(directory_path, templates, verbose, ai, include_extracted, detection_pattern, report, output_format)
    else:
        # Validate single image
        if not os.path.isfile(image_path):
            print(f"Error: The file '{image_path}' does not exist.")
            sys.exit(1)

        # Validate that the file is an image (basic check based on extension)
        valid_extensions = (".png", ".jpg", ".jpeg", ".gif", ".bmp")
        if not image_path.lower().endswith(valid_extensions):
            print(f"Error: The file '{image_path}' must be an image file ({', '.join(valid_extensions)}).")
            sys.exit(1)

        # Analyze single screenshot
        extracted_text, meta_tags = analyze_screenshot(image_path, templates, verbose, ai, include_extracted, detection_pattern)

        # Handle output
        if report:
            # Wrap single image result in a list for consistent report generation
            results = [{
                "image_path": image_path,
                "extracted_text": extracted_text,
                "meta_tags": meta_tags
            }]
            generate_report(results, output_format, verbose, include_extracted)
        else:
            if verbose:
                print("Analysis Results:")
                print(f"File Path: {image_path}")
                if verbose or include_extracted:
                    try:
                        base64_text = base64.b64encode(extracted_text.encode('utf-8')).decode('utf-8')
                        print(f"Extracted Text (Base64): {base64_text}")
                    except Exception as e:
                        print(f"Extracted Text Error: Failed to encode text to Base64: {str(e)}")
                print("Meta Tags:")
            print(format_output(meta_tags, output_format))
